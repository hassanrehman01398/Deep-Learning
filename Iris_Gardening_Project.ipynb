{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SUgodO9xWDB",
    "colab_type": "text"
   },
   "source": [
    "#Multi-Class Classification Iris Flowers Project for Mothers who love Gardening and Flowers :  Identifying Flower Types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9i-zxtSxzky",
    "colab_type": "text"
   },
   "source": [
    "# Making Preparations\n",
    "We will start off by importing all of the classes and functions we will need. This includes both the functionality we require from Keras, but also data loading from pandas as well as data preparation and model evaluation from scikit-learn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Sd_GTux-x3mQ",
    "colab_type": "code",
    "outputId": "45ba078f-d554-429c-e62f-018c2538b9a6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP4mBr52yp50",
    "colab_type": "text"
   },
   "source": [
    "#Next, we need to initialize the random number generator to a constant value (7).\n",
    "\n",
    "This is important to ensure that the results we achieve from this model can be achieved again precisely. It ensures that the stochastic process of training a neural network model can be reproduced:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aS6TdHRtytUF",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0Vwv4CEzoGX",
    "colab_type": "text"
   },
   "source": [
    "#Loading IRIS Dataset .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HUzEmAhgzvSA",
    "colab_type": "code",
    "outputId": "00774a74-ffd4-45a0-98e2-b1023c9a4342",
    "colab": {
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "ok": true,
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "status": 200.0,
       "status_text": ""
      }
     },
     "base_uri": "https://localhost:8080/",
     "height": 157.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "graphviz is already the newest version (2.40.1-2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5de2fd59-1d5b-4feb-9b49-6deab9b63735\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-5de2fd59-1d5b-4feb-9b49-6deab9b63735\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving iris.csv to iris.csv\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "!apt-get install graphviz -y\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "dataframe = pd.read_csv('iris.csv' , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "COGRoXnu1a0u",
    "colab_type": "code",
    "outputId": "39c3e10d-6444-4b4d-ed59-80110fe417e9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1105.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3               4\n",
      "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
      "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "5    5.4  3.9  1.7  0.4     Iris-setosa\n",
      "6    4.6  3.4  1.4  0.3     Iris-setosa\n",
      "7    5.0  3.4  1.5  0.2     Iris-setosa\n",
      "8    4.4  2.9  1.4  0.2     Iris-setosa\n",
      "9    4.9  3.1  1.5  0.1     Iris-setosa\n",
      "10   5.4  3.7  1.5  0.2     Iris-setosa\n",
      "11   4.8  3.4  1.6  0.2     Iris-setosa\n",
      "12   4.8  3.0  1.4  0.1     Iris-setosa\n",
      "13   4.3  3.0  1.1  0.1     Iris-setosa\n",
      "14   5.8  4.0  1.2  0.2     Iris-setosa\n",
      "15   5.7  4.4  1.5  0.4     Iris-setosa\n",
      "16   5.4  3.9  1.3  0.4     Iris-setosa\n",
      "17   5.1  3.5  1.4  0.3     Iris-setosa\n",
      "18   5.7  3.8  1.7  0.3     Iris-setosa\n",
      "19   5.1  3.8  1.5  0.3     Iris-setosa\n",
      "20   5.4  3.4  1.7  0.2     Iris-setosa\n",
      "21   5.1  3.7  1.5  0.4     Iris-setosa\n",
      "22   4.6  3.6  1.0  0.2     Iris-setosa\n",
      "23   5.1  3.3  1.7  0.5     Iris-setosa\n",
      "24   4.8  3.4  1.9  0.2     Iris-setosa\n",
      "25   5.0  3.0  1.6  0.2     Iris-setosa\n",
      "26   5.0  3.4  1.6  0.4     Iris-setosa\n",
      "27   5.2  3.5  1.5  0.2     Iris-setosa\n",
      "28   5.2  3.4  1.4  0.2     Iris-setosa\n",
      "29   4.7  3.2  1.6  0.2     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "120  6.9  3.2  5.7  2.3  Iris-virginica\n",
      "121  5.6  2.8  4.9  2.0  Iris-virginica\n",
      "122  7.7  2.8  6.7  2.0  Iris-virginica\n",
      "123  6.3  2.7  4.9  1.8  Iris-virginica\n",
      "124  6.7  3.3  5.7  2.1  Iris-virginica\n",
      "125  7.2  3.2  6.0  1.8  Iris-virginica\n",
      "126  6.2  2.8  4.8  1.8  Iris-virginica\n",
      "127  6.1  3.0  4.9  1.8  Iris-virginica\n",
      "128  6.4  2.8  5.6  2.1  Iris-virginica\n",
      "129  7.2  3.0  5.8  1.6  Iris-virginica\n",
      "130  7.4  2.8  6.1  1.9  Iris-virginica\n",
      "131  7.9  3.8  6.4  2.0  Iris-virginica\n",
      "132  6.4  2.8  5.6  2.2  Iris-virginica\n",
      "133  6.3  2.8  5.1  1.5  Iris-virginica\n",
      "134  6.1  2.6  5.6  1.4  Iris-virginica\n",
      "135  7.7  3.0  6.1  2.3  Iris-virginica\n",
      "136  6.3  3.4  5.6  2.4  Iris-virginica\n",
      "137  6.4  3.1  5.5  1.8  Iris-virginica\n",
      "138  6.0  3.0  4.8  1.8  Iris-virginica\n",
      "139  6.9  3.1  5.4  2.1  Iris-virginica\n",
      "140  6.7  3.1  5.6  2.4  Iris-virginica\n",
      "141  6.9  3.1  5.1  2.3  Iris-virginica\n",
      "142  5.8  2.7  5.1  1.9  Iris-virginica\n",
      "143  6.8  3.2  5.9  2.3  Iris-virginica\n",
      "144  6.7  3.3  5.7  2.5  Iris-virginica\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rLh77sBt1Qdw",
    "colab_type": "code",
    "outputId": "01e6d716-b9f4-4cac-a93a-f4c228613ac1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2567.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2 'Iris-setosa']\n",
      " [4.9 3.0 1.4 0.2 'Iris-setosa']\n",
      " [4.7 3.2 1.3 0.2 'Iris-setosa']\n",
      " [4.6 3.1 1.5 0.2 'Iris-setosa']\n",
      " [5.0 3.6 1.4 0.2 'Iris-setosa']\n",
      " [5.4 3.9 1.7 0.4 'Iris-setosa']\n",
      " [4.6 3.4 1.4 0.3 'Iris-setosa']\n",
      " [5.0 3.4 1.5 0.2 'Iris-setosa']\n",
      " [4.4 2.9 1.4 0.2 'Iris-setosa']\n",
      " [4.9 3.1 1.5 0.1 'Iris-setosa']\n",
      " [5.4 3.7 1.5 0.2 'Iris-setosa']\n",
      " [4.8 3.4 1.6 0.2 'Iris-setosa']\n",
      " [4.8 3.0 1.4 0.1 'Iris-setosa']\n",
      " [4.3 3.0 1.1 0.1 'Iris-setosa']\n",
      " [5.8 4.0 1.2 0.2 'Iris-setosa']\n",
      " [5.7 4.4 1.5 0.4 'Iris-setosa']\n",
      " [5.4 3.9 1.3 0.4 'Iris-setosa']\n",
      " [5.1 3.5 1.4 0.3 'Iris-setosa']\n",
      " [5.7 3.8 1.7 0.3 'Iris-setosa']\n",
      " [5.1 3.8 1.5 0.3 'Iris-setosa']\n",
      " [5.4 3.4 1.7 0.2 'Iris-setosa']\n",
      " [5.1 3.7 1.5 0.4 'Iris-setosa']\n",
      " [4.6 3.6 1.0 0.2 'Iris-setosa']\n",
      " [5.1 3.3 1.7 0.5 'Iris-setosa']\n",
      " [4.8 3.4 1.9 0.2 'Iris-setosa']\n",
      " [5.0 3.0 1.6 0.2 'Iris-setosa']\n",
      " [5.0 3.4 1.6 0.4 'Iris-setosa']\n",
      " [5.2 3.5 1.5 0.2 'Iris-setosa']\n",
      " [5.2 3.4 1.4 0.2 'Iris-setosa']\n",
      " [4.7 3.2 1.6 0.2 'Iris-setosa']\n",
      " [4.8 3.1 1.6 0.2 'Iris-setosa']\n",
      " [5.4 3.4 1.5 0.4 'Iris-setosa']\n",
      " [5.2 4.1 1.5 0.1 'Iris-setosa']\n",
      " [5.5 4.2 1.4 0.2 'Iris-setosa']\n",
      " [4.9 3.1 1.5 0.1 'Iris-setosa']\n",
      " [5.0 3.2 1.2 0.2 'Iris-setosa']\n",
      " [5.5 3.5 1.3 0.2 'Iris-setosa']\n",
      " [4.9 3.1 1.5 0.1 'Iris-setosa']\n",
      " [4.4 3.0 1.3 0.2 'Iris-setosa']\n",
      " [5.1 3.4 1.5 0.2 'Iris-setosa']\n",
      " [5.0 3.5 1.3 0.3 'Iris-setosa']\n",
      " [4.5 2.3 1.3 0.3 'Iris-setosa']\n",
      " [4.4 3.2 1.3 0.2 'Iris-setosa']\n",
      " [5.0 3.5 1.6 0.6 'Iris-setosa']\n",
      " [5.1 3.8 1.9 0.4 'Iris-setosa']\n",
      " [4.8 3.0 1.4 0.3 'Iris-setosa']\n",
      " [5.1 3.8 1.6 0.2 'Iris-setosa']\n",
      " [4.6 3.2 1.4 0.2 'Iris-setosa']\n",
      " [5.3 3.7 1.5 0.2 'Iris-setosa']\n",
      " [5.0 3.3 1.4 0.2 'Iris-setosa']\n",
      " [7.0 3.2 4.7 1.4 'Iris-versicolor']\n",
      " [6.4 3.2 4.5 1.5 'Iris-versicolor']\n",
      " [6.9 3.1 4.9 1.5 'Iris-versicolor']\n",
      " [5.5 2.3 4.0 1.3 'Iris-versicolor']\n",
      " [6.5 2.8 4.6 1.5 'Iris-versicolor']\n",
      " [5.7 2.8 4.5 1.3 'Iris-versicolor']\n",
      " [6.3 3.3 4.7 1.6 'Iris-versicolor']\n",
      " [4.9 2.4 3.3 1.0 'Iris-versicolor']\n",
      " [6.6 2.9 4.6 1.3 'Iris-versicolor']\n",
      " [5.2 2.7 3.9 1.4 'Iris-versicolor']\n",
      " [5.0 2.0 3.5 1.0 'Iris-versicolor']\n",
      " [5.9 3.0 4.2 1.5 'Iris-versicolor']\n",
      " [6.0 2.2 4.0 1.0 'Iris-versicolor']\n",
      " [6.1 2.9 4.7 1.4 'Iris-versicolor']\n",
      " [5.6 2.9 3.6 1.3 'Iris-versicolor']\n",
      " [6.7 3.1 4.4 1.4 'Iris-versicolor']\n",
      " [5.6 3.0 4.5 1.5 'Iris-versicolor']\n",
      " [5.8 2.7 4.1 1.0 'Iris-versicolor']\n",
      " [6.2 2.2 4.5 1.5 'Iris-versicolor']\n",
      " [5.6 2.5 3.9 1.1 'Iris-versicolor']\n",
      " [5.9 3.2 4.8 1.8 'Iris-versicolor']\n",
      " [6.1 2.8 4.0 1.3 'Iris-versicolor']\n",
      " [6.3 2.5 4.9 1.5 'Iris-versicolor']\n",
      " [6.1 2.8 4.7 1.2 'Iris-versicolor']\n",
      " [6.4 2.9 4.3 1.3 'Iris-versicolor']\n",
      " [6.6 3.0 4.4 1.4 'Iris-versicolor']\n",
      " [6.8 2.8 4.8 1.4 'Iris-versicolor']\n",
      " [6.7 3.0 5.0 1.7 'Iris-versicolor']\n",
      " [6.0 2.9 4.5 1.5 'Iris-versicolor']\n",
      " [5.7 2.6 3.5 1.0 'Iris-versicolor']\n",
      " [5.5 2.4 3.8 1.1 'Iris-versicolor']\n",
      " [5.5 2.4 3.7 1.0 'Iris-versicolor']\n",
      " [5.8 2.7 3.9 1.2 'Iris-versicolor']\n",
      " [6.0 2.7 5.1 1.6 'Iris-versicolor']\n",
      " [5.4 3.0 4.5 1.5 'Iris-versicolor']\n",
      " [6.0 3.4 4.5 1.6 'Iris-versicolor']\n",
      " [6.7 3.1 4.7 1.5 'Iris-versicolor']\n",
      " [6.3 2.3 4.4 1.3 'Iris-versicolor']\n",
      " [5.6 3.0 4.1 1.3 'Iris-versicolor']\n",
      " [5.5 2.5 4.0 1.3 'Iris-versicolor']\n",
      " [5.5 2.6 4.4 1.2 'Iris-versicolor']\n",
      " [6.1 3.0 4.6 1.4 'Iris-versicolor']\n",
      " [5.8 2.6 4.0 1.2 'Iris-versicolor']\n",
      " [5.0 2.3 3.3 1.0 'Iris-versicolor']\n",
      " [5.6 2.7 4.2 1.3 'Iris-versicolor']\n",
      " [5.7 3.0 4.2 1.2 'Iris-versicolor']\n",
      " [5.7 2.9 4.2 1.3 'Iris-versicolor']\n",
      " [6.2 2.9 4.3 1.3 'Iris-versicolor']\n",
      " [5.1 2.5 3.0 1.1 'Iris-versicolor']\n",
      " [5.7 2.8 4.1 1.3 'Iris-versicolor']\n",
      " [6.3 3.3 6.0 2.5 'Iris-virginica']\n",
      " [5.8 2.7 5.1 1.9 'Iris-virginica']\n",
      " [7.1 3.0 5.9 2.1 'Iris-virginica']\n",
      " [6.3 2.9 5.6 1.8 'Iris-virginica']\n",
      " [6.5 3.0 5.8 2.2 'Iris-virginica']\n",
      " [7.6 3.0 6.6 2.1 'Iris-virginica']\n",
      " [4.9 2.5 4.5 1.7 'Iris-virginica']\n",
      " [7.3 2.9 6.3 1.8 'Iris-virginica']\n",
      " [6.7 2.5 5.8 1.8 'Iris-virginica']\n",
      " [7.2 3.6 6.1 2.5 'Iris-virginica']\n",
      " [6.5 3.2 5.1 2.0 'Iris-virginica']\n",
      " [6.4 2.7 5.3 1.9 'Iris-virginica']\n",
      " [6.8 3.0 5.5 2.1 'Iris-virginica']\n",
      " [5.7 2.5 5.0 2.0 'Iris-virginica']\n",
      " [5.8 2.8 5.1 2.4 'Iris-virginica']\n",
      " [6.4 3.2 5.3 2.3 'Iris-virginica']\n",
      " [6.5 3.0 5.5 1.8 'Iris-virginica']\n",
      " [7.7 3.8 6.7 2.2 'Iris-virginica']\n",
      " [7.7 2.6 6.9 2.3 'Iris-virginica']\n",
      " [6.0 2.2 5.0 1.5 'Iris-virginica']\n",
      " [6.9 3.2 5.7 2.3 'Iris-virginica']\n",
      " [5.6 2.8 4.9 2.0 'Iris-virginica']\n",
      " [7.7 2.8 6.7 2.0 'Iris-virginica']\n",
      " [6.3 2.7 4.9 1.8 'Iris-virginica']\n",
      " [6.7 3.3 5.7 2.1 'Iris-virginica']\n",
      " [7.2 3.2 6.0 1.8 'Iris-virginica']\n",
      " [6.2 2.8 4.8 1.8 'Iris-virginica']\n",
      " [6.1 3.0 4.9 1.8 'Iris-virginica']\n",
      " [6.4 2.8 5.6 2.1 'Iris-virginica']\n",
      " [7.2 3.0 5.8 1.6 'Iris-virginica']\n",
      " [7.4 2.8 6.1 1.9 'Iris-virginica']\n",
      " [7.9 3.8 6.4 2.0 'Iris-virginica']\n",
      " [6.4 2.8 5.6 2.2 'Iris-virginica']\n",
      " [6.3 2.8 5.1 1.5 'Iris-virginica']\n",
      " [6.1 2.6 5.6 1.4 'Iris-virginica']\n",
      " [7.7 3.0 6.1 2.3 'Iris-virginica']\n",
      " [6.3 3.4 5.6 2.4 'Iris-virginica']\n",
      " [6.4 3.1 5.5 1.8 'Iris-virginica']\n",
      " [6.0 3.0 4.8 1.8 'Iris-virginica']\n",
      " [6.9 3.1 5.4 2.1 'Iris-virginica']\n",
      " [6.7 3.1 5.6 2.4 'Iris-virginica']\n",
      " [6.9 3.1 5.1 2.3 'Iris-virginica']\n",
      " [5.8 2.7 5.1 1.9 'Iris-virginica']\n",
      " [6.8 3.2 5.9 2.3 'Iris-virginica']\n",
      " [6.7 3.3 5.7 2.5 'Iris-virginica']\n",
      " [6.7 3.0 5.2 2.3 'Iris-virginica']\n",
      " [6.3 2.5 5.0 1.9 'Iris-virginica']\n",
      " [6.5 3.0 5.2 2.0 'Iris-virginica']\n",
      " [6.2 3.4 5.4 2.3 'Iris-virginica']\n",
      " [5.9 3.0 5.1 1.8 'Iris-virginica']]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataframe.values\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhzSOyDf0ytI",
    "colab_type": "text"
   },
   "source": [
    "#We can then split the attributes (columns) into input variables (X) and output variables (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CXybMklH00S_",
    "colab_type": "code",
    "outputId": "e8e87877-a002-43e8-82f7-35ab6461100e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3162.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "x = dataset[:,0:4].astype(float)\n",
    "y = dataset[:,4]\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaufAt1c3o4l",
    "colab_type": "text"
   },
   "source": [
    "#The output variable contains three different string values.\n",
    "1.  Iris-setosa\n",
    "2.  Iris-versicolor\n",
    "3.  Iris-virginica\n",
    "\n",
    "#We can turn this into a one-hot encoded binary matrix for each data instance that would look as follows:\n",
    "\n",
    "Iris-setosa,\tIris-versicolor,\tIris-virginica\n",
    "\n",
    "1\t\t             ,            0\t\t\t        ,           0\n",
    "\n",
    "0\t               ,            1\t\t\t        ,           0\n",
    "\n",
    "0\t\t             ,            0\t\t\t        ,           1\n",
    "\n",
    "#We can do this by first encoding the strings consistently to integers using the scikit-learn class LabelEncoder. Then convert the vector of integers to a one hot encoding using the Keras function to_categorical().\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aIpsKiOJ5I04",
    "colab_type": "code",
    "outputId": "f9c38933-b7ab-49c0-82dd-0310dd0d728f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2669.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "le = LabelEncoder()\n",
    "encoded_Y = le.fit_transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "print(encoded_Y)\n",
    "print(\"\\n\" +str(dummy_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ftm8gb3N6IYQ",
    "colab_type": "text"
   },
   "source": [
    "#Define the Neural Network Baseline Model\n",
    "\n",
    "\n",
    "  \n",
    "* Below is a function that will create a baseline neural network for the iris classification problem. It creates a simple fully connected network with one hidden layer  that contains 8 neurons.\n",
    "\n",
    "* The hidden layer uses a rectifier activation function, which is a good practice. Because we used a one-hot encoding for our iris dataset, the output layer must create 3 output values, one for each class. The output value with the largest value will be taken as the class predicted by the model.\n",
    "The network topology of this simple one-layer neural network can be summarized as:\n",
    "\n",
    "* 4 inputs -> [8 hidden nodes] -> 3 outputs\n",
    "\n",
    "* Note that we use a “softmax” activation function in the output layer. This is to ensure the output values are in the range of 0 and 1 and may be used as predicted probabilities.\n",
    "\n",
    "* Finally, the network uses the efficient Adam gradient descent optimization algorithm with a logarithmic loss function, which is called “categorical_crossentropy” in Keras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7suFbC2H6R2l",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t\n",
    "  # create model\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(8 , activation = 'relu' , input_dim = 4 ))\n",
    "  model.add(layers.Dense(3 , activation = 'softmax'))\n",
    "\t\n",
    "\n",
    "\t# Compile model\n",
    "  model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics= ['accuracy'])\n",
    "\t\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVffe-Mh_Alv",
    "colab_type": "text"
   },
   "source": [
    "# We can now create our KerasClassifier for use in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JArxD8m7_ESj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqFdeAyN_Xt2",
    "colab_type": "text"
   },
   "source": [
    "#Evaluate The Model with k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "uFZ1ctVo_Z8e",
    "colab_type": "code",
    "outputId": "d7b0c61f-a5be-4458-8ebe-0e9fd4646935",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 96.00% (5.33%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" First we can define the model evaluation procedure. Here, we set the number of folds to be 10 (an excellent default)\n",
    "and to shuffle the data before partitioning it. \"\"\"\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Now we can evaluate our model (estimator) on our dataset (X and dummy_y) using a 10-fold cross-validation procedure (kfold).\n",
    "\n",
    "\"\"\" Evaluating the model only takes approximately 10 seconds and returns an object that describes the evaluation of the 10 constructed\n",
    "models for each of the splits of the dataset. \"\"\"\n",
    "\n",
    "results = cross_val_score(estimator, x, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_yNrwLXBPco",
    "colab_type": "text"
   },
   "source": [
    "#Tuning Layers and Number of Neurons in The Model\n",
    "\n",
    "There are many things to tune on a neural network, such as the weight initialization, activation functions, optimization procedure and so on.\n",
    "\n",
    "One aspect that may have an outsized effect is the structure of the network itself called the network topology. In this section, we take a look at two experiments on the structure of the network: making it smaller and making it larger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLWLmPEeD3hf",
    "colab_type": "text"
   },
   "source": [
    "#Evaluate Smaller Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "DBvNfjJwBKIc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def create_smaller():\n",
    "\t\n",
    "  # create model\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(4 , activation = 'relu' , input_dim = 4 ))\n",
    "  model.add(layers.Dense(3 , activation = 'softmax'))\n",
    "\t\n",
    "\n",
    "\t# Compile model\n",
    "  model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics= ['accuracy'])\n",
    "\t\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "lMKO5DjAERoI",
    "colab_type": "code",
    "outputId": "f7046765-1d87-4298-927f-33779df9d3aa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 82.67% (26.87%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_smaller, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, x, dummy_y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UHjCQZbFBXT",
    "colab_type": "text"
   },
   "source": [
    "#Evaluate Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "iBMUJwwjFKaX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def create_larger():\n",
    "\t\n",
    "  # create model\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(8 , activation = 'relu' , input_dim = 4 ))\n",
    "  model.add(layers.Dense(4 , activation = 'relu'))\n",
    "  model.add(layers.Dense(3 , activation = 'softmax'))\n",
    "\t\n",
    "\n",
    "\t# Compile model\n",
    "  model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics= ['accuracy'])\n",
    "\t\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "zBCBlbnEFlfM",
    "colab_type": "code",
    "outputId": "31b67de8-02b6-48f3-9aac-7d027d51837c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 93.33% (11.93%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, x, dummy_y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZcHn9k-La7P",
    "colab_type": "text"
   },
   "source": [
    "#Rewriting the code using the Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-6Oa5DOPLhzj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "def func_API():\n",
    "    \n",
    "  # Build model\n",
    "\n",
    "  input = keras.Input(shape =(4,))\n",
    "  x = layers.Dense(8 , activation = 'relu')(input)\n",
    "  output = layers.Dense(3 , activation = 'softmax')(x)\n",
    "  model = keras.Model(input ,output)\n",
    "\n",
    "  # Compiled Model\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam',   metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "IBVVNG6nL8ZX",
    "colab_type": "code",
    "outputId": "fdb872f9-1dd1-413d-80ac-594706e0abad",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional API method : 99.33% (2.00%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=func_API, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, x, dummy_y, cv=kfold)\n",
    "print(\"Functional API method : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_n4dd8OiM0-u",
    "colab_type": "text"
   },
   "source": [
    "#Rewriting the code by doing Model Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "zYnI-zFFNChC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras import layers\n",
    "\n",
    "def SubClass_API():\n",
    "\n",
    "  class MyModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self):\n",
    "      super(MyModel, self).__init__()\n",
    "    \n",
    "      self.dense1 = layers.Dense(4 , activation = 'relu')\n",
    "      self.dense2 = layers.Dense(8 , activation = 'relu')\n",
    "      self.dense3 = layers.Dense(3 , activation = 'softmax')\n",
    "  \n",
    "    def call(self , inputs):\n",
    "  \n",
    "      x = self.dense1(inputs)\n",
    "      x = self.dense2(x)\n",
    "  \n",
    "      return self.dense3(x) \n",
    "\n",
    "  model = MyModel()\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam',   metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "estimator = KerasClassifier(build_fn=SubClass_API, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, x, dummy_y, cv=kfold)\n",
    "print(\"Model SubClass API method : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6ncG-LSRpwC",
    "colab_type": "text"
   },
   "source": [
    "# Rewriting the code without using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "mzQkJ4Ef-I3D",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85.0
    },
    "outputId": "7cc2fe2c-f50d-47db-d2de-4c1a3d098691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(x) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = dummy_y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([x[:i * num_val_samples],x[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([dummy_y[:i * num_val_samples],dummy_y[(i + 1) * num_val_samples:]],axis=0)\n",
    "model = baseline_model()\n",
    "model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Jaq6pnaW-J0C",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "2beb36dc-5ee2-404c-8f89-f9bfc3ea99ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7837837837837838]\n"
     ]
    }
   ],
   "source": [
    "print(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "P7ZO9muECGs6",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Iris_Gardening_Project.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
