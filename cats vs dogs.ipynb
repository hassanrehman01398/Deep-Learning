{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os , shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" After extracting cats and dogs dataset we have two sub folders (test1 and train) inside the main folder \n",
    "(which i named as \"catdog\") . So, i have assigned two variables for each sub folder .\n",
    "Because of this step we wont get any kinda file path error at the time of copying selected images in new folder \"\"\"\n",
    "\n",
    "original_train_dataset_dir = '/Users/sk1/.keras/datasets/catdog/train'   #adding sub (train) at the end \n",
    "original_test_dataset_dir = '/Users/sk1/.keras/datasets/catdog/test1'    #adding sub (test1) at the end\n",
    " \n",
    "#creating new folder as cats_dogs_selected\n",
    "\n",
    "base_dir = 'F:/Books/kaggle_datasets/cats_dogs_selected'  \n",
    "os.mkdir(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating 3 sub folders \n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a folder \"cats\" inside the \"train\" folder \n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a folder \"dogs\" inside the \"train\" folder\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a folder \"cats\" inside the \"validation\" folder \n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a folder \"dogs\" inside the \"validation\" folder\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a folder \"cats\" inside the \"test\" folder\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a folder \"dogs\" inside the \"test\" folder\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copying first 1000 images of cats for training in \"cats_dogs_selected --> train --> cats\" folder \n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copying 500 images for validation after the series of 1000 images of cats in \"cats_dogs_selected --> validation --> cats\" folder\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copying 500 images for testing after the series of 1500 images of cats in \"cats_dogs_selected --> test--> cats\" folder\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copying first 1000 images of dogs for training in \"cats_dogs_selected --> train --> dogs\" folder \n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copying 500 images for validation after the series of 1000 images of dogs in \"cats_dogs_selected --> validation --> dogs\" folder\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copying 500 images for testing after the series of 1500 images of dogs in \"cats_dogs_selected --> test--> dogs\" folder\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 1000\n",
      "total training dog images: 1000\n"
     ]
    }
   ],
   "source": [
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total validation cat images: 500\n",
      "total validation dog images: 500\n"
     ]
    }
   ],
   "source": [
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test cat images: 500\n",
      "total test dog images: 500\n"
     ]
    }
   ],
   "source": [
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150, 150),batch_size=20,class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(150, 150), batch_size=20, class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "labels batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 276s 3s/step - loss: 0.6910 - acc: 0.5335 - val_loss: 0.6888 - val_acc: 0.5290\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 283s 3s/step - loss: 0.6632 - acc: 0.5920 - val_loss: 0.6378 - val_acc: 0.6150\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 257s 3s/step - loss: 0.5996 - acc: 0.6815 - val_loss: 0.6099 - val_acc: 0.6460\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 262s 3s/step - loss: 0.5646 - acc: 0.7190 - val_loss: 0.6449 - val_acc: 0.6190\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 261s 3s/step - loss: 0.5367 - acc: 0.7200 - val_loss: 0.5836 - val_acc: 0.6840\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 279s 3s/step - loss: 0.5122 - acc: 0.7460 - val_loss: 0.5651 - val_acc: 0.6890\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 305s 3s/step - loss: 0.4810 - acc: 0.7740 - val_loss: 0.5773 - val_acc: 0.6770\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 315s 3s/step - loss: 0.4646 - acc: 0.7795 - val_loss: 0.5513 - val_acc: 0.7060\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 329s 3s/step - loss: 0.4367 - acc: 0.7920 - val_loss: 0.5571 - val_acc: 0.7040\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 285s 3s/step - loss: 0.4161 - acc: 0.8170 - val_loss: 0.5678 - val_acc: 0.7100\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 274s 3s/step - loss: 0.4008 - acc: 0.8190 - val_loss: 0.6006 - val_acc: 0.6970\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 261s 3s/step - loss: 0.3735 - acc: 0.8440 - val_loss: 0.5435 - val_acc: 0.7230\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 274s 3s/step - loss: 0.3451 - acc: 0.8505 - val_loss: 0.6148 - val_acc: 0.7220\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 257s 3s/step - loss: 0.3258 - acc: 0.8610 - val_loss: 0.6362 - val_acc: 0.7040\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 247s 2s/step - loss: 0.3029 - acc: 0.8680 - val_loss: 0.6143 - val_acc: 0.7180\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 227s 2s/step - loss: 0.2840 - acc: 0.8845 - val_loss: 0.5855 - val_acc: 0.7330\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 224s 2s/step - loss: 0.2650 - acc: 0.8925 - val_loss: 0.5897 - val_acc: 0.7120\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 223s 2s/step - loss: 0.2361 - acc: 0.9075 - val_loss: 0.6113 - val_acc: 0.7250\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 237s 2s/step - loss: 0.2198 - acc: 0.9190 - val_loss: 0.7048 - val_acc: 0.7250\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 235s 2s/step - loss: 0.2046 - acc: 0.9220 - val_loss: 0.6526 - val_acc: 0.7160\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 262s 3s/step - loss: 0.1850 - acc: 0.9285 - val_loss: 0.6665 - val_acc: 0.7260\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 295s 3s/step - loss: 0.1539 - acc: 0.9455 - val_loss: 0.7407 - val_acc: 0.7250\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 294s 3s/step - loss: 0.1469 - acc: 0.9450 - val_loss: 0.7205 - val_acc: 0.7250\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 279s 3s/step - loss: 0.1355 - acc: 0.9510 - val_loss: 0.7764 - val_acc: 0.7280\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 297s 3s/step - loss: 0.1121 - acc: 0.9605 - val_loss: 0.7541 - val_acc: 0.7280\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 301s 3s/step - loss: 0.0997 - acc: 0.9670 - val_loss: 0.8306 - val_acc: 0.7180\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 309s 3s/step - loss: 0.0841 - acc: 0.9745 - val_loss: 0.9273 - val_acc: 0.7190\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 318s 3s/step - loss: 0.0757 - acc: 0.9765 - val_loss: 0.9639 - val_acc: 0.7180\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 290s 3s/step - loss: 0.0685 - acc: 0.9775 - val_loss: 0.8642 - val_acc: 0.7300\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 273s 3s/step - loss: 0.0532 - acc: 0.9850 - val_loss: 0.9474 - val_acc: 0.7290\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch=100,epochs=30,validation_data=validation_generator,\n",
    "                              validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
